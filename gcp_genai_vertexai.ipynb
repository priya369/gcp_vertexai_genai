{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b55a71-e585-4c9e-8dcf-c11d2651fa79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54fef19-0140-4f91-b0e8-beea9e0fe2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace the `GOOGLE_CLOUD_PROJECT` and `GOOGLE_CLOUD_LOCATION` values\n",
    "# with appropriate values for your project.\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"data-oasis-472909-u4\"\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6897f976-0bea-4a51-b41a-fb5ea2b99576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\anaconda3\\envs\\gcp-vertexai\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.service_account import Credentials\n",
    "api_key_path=\"data-oasis-472909-u4-fe397a2982e5.json\"\n",
    "\n",
    "credential=Credentials.from_service_account_file(\n",
    "    api_key_path,scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "PROJECT_ID='data-oasis-472909-u4'\n",
    "REGION='us-central1'\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    credentials=credential\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20b98b9-79b4-4715-8350-37a5d9aaa093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name: projects/191979586562/locations/us-central1/batchPredictionJobs/8653095264363479040\n",
      "Job state: JOB_STATE_PENDING\n",
      "Job state: JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from google import genai\n",
    "from google.genai.types import CreateBatchJobConfig, JobState, HttpOptions\n",
    "\n",
    "client = genai.Client(http_options=HttpOptions(api_version=\"v1\"),credentials=credential)\n",
    "output_uri = \"bq://data-oasis-472909-u4.mlops_project.embedding\"\n",
    "# See the documentation: https://googleapis.github.io/python-genai/genai.html#genai.batches.Batches.create\n",
    "job = client.batches.create(\n",
    "    model=\"text-embedding-005\",\n",
    "    # Source link: https://storage.cloud.google.com/cloud-samples-data/generative-ai/embeddings/embeddings_input.jsonl\n",
    "    src=\"gs://cloud-samples-data/generative-ai/embeddings/embeddings_input.jsonl\",\n",
    "    config=CreateBatchJobConfig(dest=output_uri),\n",
    ")\n",
    "print(f\"Job name: {job.name}\")\n",
    "print(f\"Job state: {job.state}\")\n",
    "# Example response:\n",
    "# Job name: projects/.../locations/.../batchPredictionJobs/9876453210000000000\n",
    "# Job state: JOB_STATE_PENDING\n",
    "\n",
    "# See the documentation: https://googleapis.github.io/python-genai/genai.html#genai.types.BatchJob\n",
    "completed_states = {\n",
    "    JobState.JOB_STATE_SUCCEEDED,\n",
    "    JobState.JOB_STATE_FAILED,\n",
    "    JobState.JOB_STATE_CANCELLED,\n",
    "    JobState.JOB_STATE_PAUSED,\n",
    "}\n",
    "\n",
    "while job.state not in completed_states:\n",
    "    time.sleep(30)\n",
    "    job = client.batches.get(name=job.name)\n",
    "    print(f\"Job state: {job.state}\")\n",
    "    if job.state == JobState.JOB_STATE_FAILED:\n",
    "        print(f\"Error: {job.error}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a725144-4ae6-4c6f-8b7d-2b42daafda35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name: projects/191979586562/locations/us-central1/batchPredictionJobs/716640015169355776\n",
      "Job state: JOB_STATE_PENDING\n",
      "Job state: JOB_STATE_RUNNING\n",
      "Job state: JOB_STATE_RUNNING\n",
      "Job state: JOB_STATE_RUNNING\n",
      "Job state: JOB_STATE_RUNNING\n",
      "Job state: JOB_STATE_RUNNING\n",
      "Job state: JOB_STATE_RUNNING\n",
      "Job state: JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from google import genai\n",
    "from google.genai.types import CreateBatchJobConfig, JobState, HttpOptions\n",
    "\n",
    "client = genai.Client(http_options=HttpOptions(api_version=\"v1\"),credentials=credential)\n",
    "# TODO(developer): Update and un-comment below line\n",
    "output_uri = \"bq://data-oasis-472909-u4.mlops_project.text_generation\"\n",
    "\n",
    "# See the documentation: https://googleapis.github.io/python-genai/genai.html#genai.batches.Batches.create\n",
    "job = client.batches.create(\n",
    "    # To use a tuned model, set the model param to your tuned model using the following format:\n",
    "    # model=\"projects/{PROJECT_ID}/locations/{LOCATION}/models/{MODEL_ID}\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    # Source link: https://storage.cloud.google.com/cloud-samples-data/batch/prompt_for_batch_gemini_predict.jsonl\n",
    "    src=\"gs://cloud-samples-data/batch/prompt_for_batch_gemini_predict.jsonl\",\n",
    "    config=CreateBatchJobConfig(dest=output_uri),\n",
    ")\n",
    "print(f\"Job name: {job.name}\")\n",
    "print(f\"Job state: {job.state}\")\n",
    "# Example response:\n",
    "# Job name: projects/.../locations/.../batchPredictionJobs/9876453210000000000\n",
    "# Job state: JOB_STATE_PENDING\n",
    "\n",
    "# See the documentation: https://googleapis.github.io/python-genai/genai.html#genai.types.BatchJob\n",
    "completed_states = {\n",
    "    JobState.JOB_STATE_SUCCEEDED,\n",
    "    JobState.JOB_STATE_FAILED,\n",
    "    JobState.JOB_STATE_CANCELLED,\n",
    "    JobState.JOB_STATE_PAUSED,\n",
    "}\n",
    "\n",
    "while job.state not in completed_states:\n",
    "    time.sleep(30)\n",
    "    job = client.batches.get(name=job.name)\n",
    "    print(f\"Job state: {job.state}\")\n",
    "# Example response:\n",
    "# Job state: JOB_STATE_PENDING\n",
    "# Job state: JOB_STATE_RUNNING\n",
    "# Job state: JOB_STATE_RUNNING\n",
    "# ...\n",
    "# Job state: JOB_STATE_SUCCEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd633a-711b-41be-86eb-6168e2d5169e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vertexai",
   "language": "python",
   "name": "gcp-vertexai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
